# Use application-temp.properties for temporary environment
# This file won't be committed to the repository!
spring.profiles.active=temp

spring.application.name=demo-langchain4j-caac-no-crud

# server.port=9014
server.servlet.context-path=/caac

# Database standard value: jdbc:h2:mem:testdb
spring.h2.console.enabled=true

# Standard values for H2 database
# spring.datasource.url=jdbc:h2:mem:testdb "Random from 2.3.x"
# spring.datasource.driverClassName=org.h2.Driver
# spring.datasource.username=sa
# spring.datasource.password=
# spring.jpa.database-platform=org.hibernate.dialect.H2Dialect

spring.datasource.url=jdbc:h2:mem:testdb

spring.jpa.hibernate.ddl-auto=validate

logging.level.org.springframework.transaction.interceptor=TRACE
logging.level.org.hibernate.SQL=DEBUG
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=TRACE

logging.level.dev.langchain4j=TRACE
logging.level.dev.ai4j.openai4j=DEBUG

spring.jpa.properties.javax.persistence.schema-generation.scripts.action=create
spring.jpa.properties.javax.persistence.schema-generation.scripts.create-target=target/create.sql
spring.jpa.properties.javax.persistence.schema-generation.scripts.create-source=metadata

# Standard values for Flyway
# spring.flyway.locations=classpath:db/migration
# spring.flyway.url=jdbc:postgresql://localhost:5432/testdb
# spring.flyway.user=postgres
# spring.flyway.password=admin

spring.flyway.enabled=true

# Langchain4j configuration
langchain4j.llm.provider=ollama
langchain4j.memory.provider=ollama
langchain4j.memory.type=in-memory

# Customer agent
langchain4j.ollama.chat-model.customer.base-url=http://localhost:11434
#langchain4j.ollama.chat-model.customer.model-name=MFDoom/deepseek-r1-tool-calling:14b
langchain4j.ollama.chat-model.customer.model-name=llama3.2
#langchain4j.ollama.chat-model.customer.model-name=MFDoom/deepseek-r1-tool-calling
langchain4j.ollama.chat-model.customer.log-requests=true
langchain4j.ollama.chat-model.customer.log-responses=true
langchain4j.ollama.chat-model.customer.temperature=0.4

# langchain4j.open-ai.chat-model.customer.base-url=https://api.openai.com/v1
langchain4j.open-ai.chat-model.customer.base-url=https://api.groq.com/openai/v1
langchain4j.open-ai.chat-model.customer.api-key=${OPENAI_API_KEY}
langchain4j.open-ai.chat-model.customer.model-name=llama-3.3-70b-versatile
# langchain4j.open-ai.chat-model.customer.model-name=gpt-4o-mini
langchain4j.open-ai.chat-model.customer.log-requests=true
langchain4j.open-ai.chat-model.customer.log-responses=true
langchain4j.open-ai.chat-model.customer.temperature=0.5

# Protector agent
langchain4j.ollama.chat-model.protector.base-url=http://localhost:11434
langchain4j.ollama.chat-model.protector.model-name=llama-guard3:8b
langchain4j.ollama.chat-model.protector.log-requests=true
langchain4j.ollama.chat-model.protector.log-responses=true
langchain4j.ollama.chat-model.protector.temperature=0.0

# TextCreator agent
langchain4j.ollama.chat-model.textcreator.base-url=http://localhost:11434
langchain4j.ollama.chat-model.textcreator.model-name=phi4
langchain4j.ollama.chat-model.textcreator.log-requests=true
langchain4j.ollama.chat-model.textcreator.log-responses=true
langchain4j.ollama.chat-model.textcreator.temperature=0.4

# Twilio Account
twilio.account.sid=YOUR_ACCOUNT_SID
twilio.auth.token=YOUR_AUTH_TOKEN
twilio.whatsapp.number=whatsapp:+xxxxxxxxxx